# GPT-123M 模型配置文件 - 面向单卡调试的轻量级 GPT-2 架构

model_family: "gpt2"
model_name: "gpt_123m"

vocab_size: 50257
n_layer: 12
n_head: 12
n_embd: 768
block_size: 1024

attn_dropout: 0.0
resid_dropout: 0.1
mlp_multiplier: 4.0
activation: "gelu"
layer_norm_eps: 1e-5
qkv_bias: true
use_flash: true
pad_token_id: null
output_hidden_states: false
output_attentions: false

