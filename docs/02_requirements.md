# 2. 项目需求规格 (Project Requirements)

本文档详细定义了“大语言模型训练框架”项目必须满足的功能性需求和工程性需求。这些需求是项目开发和验收的核心依据。

---

### 2.1 功能性需求 (Functional Requirements)

功能性需求描述了系统必须具备的核心能力。

#### FR-1: 支持核心训练任务
系统必须支持以下三种主流的离线训练任务：
- **FR-1.1: 预训练 (Pre-training)**: 能够在大规模无标签文本语料上进行自回归语言模型的预训练。
- **FR-1.2: 指令微调 (Supervised Fine-Tuning, SFT)**: 能够在使用“指令-响应”格式的数据集上对预训练模型进行微调。
- **FR-1.3: 直接偏好优化 (Direct Preference Optimization, DPO)**: 能够在使用“选择-拒绝”格式的偏好数据集上，对模型进行对齐微调。

#### FR-2: 支持多尺度模型
系统必须能够通过修改配置文件，在**不改动任何 Python 代码**的前提下，支持不同参数规模的 GPT 风格模型的训练。
- **FR-2.1: 规模定义**: 必须支持从亿级（如 125M）到十亿级（如 1B）参数规模的模型。
- **FR-2.2: 配置驱动**: 模型的层数、头数、嵌入维度等所有结构参数必须在独立的模型配置文件中定义。

#### FR-3: 支持混合数据源
系统的数据处理模块必须能够处理来自不同来源的数据。
- **FR-3.1: 本地数据**: 必须能加载存储在本地文件系统上的小规模调试数据（如 `.jsonl`, `.json` 文件）。
- **FR-3.2: 流式数据**: 必须支持从云端（如 Hugging Face Hub, AWS S3）以流式（streaming）方式读取大规模数据集，避免将整个数据集下载到本地。
- **FR-3.3: 配置切换**: 数据源的类型（本地 vs. 流式）和路径必须通过训练配置文件进行指定。

#### FR-4: 支持分布式训练
系统必须能在不同硬件环境下稳定运行，并支持基础的并行策略。
- **FR-4.1: 单卡环境**: 必须能在单张消费级或数据中心级 GPU（如 1x 4090, 1x V100）上正确运行。
- **FR-4.2: 单机多卡环境**: 必须能在单台服务器的多张 GPU（如 4x V100）上稳定运行。
- **FR-4.3: 数据并行**: 在多卡环境下，必须支持标准的分布式数据并行（Distributed Data Parallel, DDP）策略。

---

### 2.2 工程性需求 (Non-Functional / Engineering Requirements)

工程性需求定义了系统的质量属性和开发标准。

#### ER-1: 代码与配置分离
系统的设计必须严格遵循代码与配置分离的原则。
- **ER-1.1: 逻辑代码**: `src/` 目录下的 Python 代码负责实现“如何做”的业务逻辑。
- **ER-1.2: 参数配置**: `configs/` 目录下的 YAML 文件负责定义“做什么”的实验参数。任何实验的调整（如学习率、模型大小、数据集）都应通过修改配置实现。

#### ER-2: 模块化与高内聚
代码结构必须是模块化的，每个模块职责单一、接口清晰。
- **ER-2.1: 职责划分**: 数据处理 (`dataset`)、模型定义 (`model`)、训练驱动 (`trainer`) 等核心模块必须在物理上分离，并有明确的职责边界。
- **ER-2.2: 低耦合**: 模块间的交互应通过清晰的接口（如函数参数、配置对象）进行，避免隐式的依赖和全局状态。

#### ER-3: 可复现性与健壮性
系统必须保证实验结果的可复现性，并具备从中断中恢复的能力。
- **ER-3.1: 随机性控制**: 必须提供机制来固定所有相关的随机种子（Python, NumPy, PyTorch），以保证在相同配置和环境下运行两次的结果完全一致。
- **ER-3.2: 检查点机制 (Checkpointing)**: 必须实现完善的检查点保存与恢复机制。系统应能定期保存训练状态（模型权重、优化器状态、迭代步数等），并能从最新的检查点无缝恢复训练，以应对意外中断。